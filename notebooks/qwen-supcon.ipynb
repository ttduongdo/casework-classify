{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41bf5a16-becb-466e-b656-c587510f9180",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2feaa6-80cb-4d28-ae1b-7b9b49025b44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dothuyduong/Documents/casework-classify/env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# import necessary libraries\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "from typing import List, Dict, Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm as progress\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# %pip install torch transformers\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    classification_report,\n",
    ")\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "from typing import Optional, Literal\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from typing import List\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7e96c6-1320-443c-a75f-eaf249bee049",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMB_MODEL = \"Qwen/Qwen3-Embedding-8B\"\n",
    "\n",
    "# Make call to Data\n",
    "# Ensure that messages_by_top_agency.csv is in the parent directory\n",
    "# This is assuming that the messages have already been created\n",
    "DATA_PATH = os.environ.get(\"DATA_PATH\", \"../messages_by_top_agency.csv\")\n",
    "TEXT_COL = os.environ.get(\"TEXT_COL\", \"message\")\n",
    "LABEL_COLS = [\"top_agency\"]\n",
    "\n",
    "# Threshold for \"threshold\" method (cosine)\n",
    "OTHER_THRESHOLD = float(os.environ.get(\"OTHER_THRESHOLD\", \"0.50\"))\n",
    "\n",
    "# Seed\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9ec154-45d3-4935-a8d0-f66f617354c9",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "faa77abd-b95a-4866-b1c9-18e015a286be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(s: str) -> str:\n",
    "    \"\"\"\n",
    "    checks input type, lowercases the text, strip, collapses all whitespace\n",
    "    \"\"\"\n",
    "    # type check\n",
    "    if not isinstance(s, str):\n",
    "        return \"\"\n",
    "    # normalize\n",
    "    s = s.lower().strip()\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "    return s\n",
    "\n",
    "\n",
    "def load_data(path: str, text_col: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load data from a CSV file, check for the presence of the text column, and normalize the text data.\n",
    "    \"\"\"\n",
    "    # load\n",
    "    df = pd.read_csv(path)\n",
    "    # check columns\n",
    "    if text_col not in df.columns:\n",
    "        raise KeyError(f\"Missing columns: {text_col}\")\n",
    "    # normalize\n",
    "    df = df.copy()\n",
    "    df = df.dropna(subset=[text_col])\n",
    "    df[text_col] = df[text_col].map(normalize)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f669d2a6-2bd0-454c-860b-d8058d3fe475",
   "metadata": {},
   "source": [
    "## Titan Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e8cac75-f153-4662-a5fd-9e5c739d40f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "_SBERT = None\n",
    "\n",
    "def sbert_client(model_name: str = EMB_MODEL):\n",
    "    \"\"\"Create/load a Sentence-BERT model (CPU by default).\"\"\"\n",
    "    global _SBERT\n",
    "    if _SBERT is None:\n",
    "        _SBERT = SentenceTransformer(model_name)\n",
    "    return _SBERT\n",
    "\n",
    "def embed_one(\n",
    "    # Single text to embedding vector\n",
    "    text: str,\n",
    "    client=None,\n",
    "    model_id: str = EMB_MODEL,\n",
    "    *,\n",
    "    # Embedding parameters\n",
    "    dimensions: Optional[int] = None,   # 256 / 512 / 1024\n",
    "    normalize: bool = True,             # Normalization by Titan v2\n",
    "    # Retry parameters\n",
    "    max_retries: int = 3,\n",
    "    backoff_base: float = 1.5,\n",
    ") -> np.ndarray:\n",
    "    \"\"\" Embed a single text into a vector.\"\"\"\n",
    "    if client is None:\n",
    "        client = sbert_client(model_id)\n",
    "\n",
    "    # Handle None or NaN input\n",
    "    if text is None or (isinstance(text, float) and np.isnan(text)):\n",
    "        text = \"\"\n",
    "    text = str(text)\n",
    "\n",
    "    vec = client.encode(\n",
    "        [text],\n",
    "        convert_to_numpy=True,\n",
    "        normalize_embeddings=normalize,\n",
    "        show_progress_bar=False,\n",
    "    )[0].astype(np.float32)\n",
    "\n",
    "    # Optional dimensions\n",
    "    if dimensions is not None and vec.shape[0] != dimensions:\n",
    "        raise ValueError(\n",
    "            f\"dimensions={dimensions} requested, but SBERT '{model_id}' outputs {vec.shape[0]} dims.\"\n",
    "        )\n",
    "\n",
    "def embed_all(\n",
    "    texts: List[str],\n",
    "    *,\n",
    "    dimensions: Optional[int] = None,\n",
    "    normalize: bool = True,\n",
    "    batch_size: int = 64,\n",
    "    show_progress_bar: bool = True,\n",
    "    model_id: str = EMB_MODEL,\n",
    ") -> np.ndarray:\n",
    "    \"\"\" Embed a list of texts into vectors.\"\"\"\n",
    "    client = sbert_client(model_id)\n",
    "\n",
    "    safe_texts = []\n",
    "    for t in texts:\n",
    "        if t is None or (isinstance(t, float) and np.isnan(t)):\n",
    "            safe_texts.append(\"\")\n",
    "        else:\n",
    "            safe_texts.append(str(t))\n",
    "\n",
    "    X = client.encode(\n",
    "        safe_texts,\n",
    "        batch_size=batch_size,\n",
    "        convert_to_numpy=True,\n",
    "        normalize_embeddings=normalize,\n",
    "        show_progress_bar=show_progress_bar,\n",
    "    ).astype(np.float32)\n",
    "\n",
    "    if dimensions is not None and X.shape[1] != dimensions:\n",
    "        raise ValueError(\n",
    "            f\"dimensions={dimensions} requested, but SBERT '{model_id}' outputs {X.shape[1]} dims.\"\n",
    "        )\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6b5e0a-84ae-4b32-b917-c5995d5e608b",
   "metadata": {},
   "source": [
    "## Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d776fc9b-70d5-4fa2-9880-83f32212ecfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_indices(\n",
    "    n: int,\n",
    "    # Split ratios by train, val, test\n",
    "    ratios: Tuple[float, float, float] = (0.6, 0.2, 0.2),\n",
    "    seed: int = SEED,\n",
    "):\n",
    "    \"\"\" Split indices into train/val/test sets based on given ratios. \"\"\"\n",
    "    # Shuffle indices\n",
    "    rng = np.random.RandomState(seed)\n",
    "    idx = np.arange(n)\n",
    "    rng.shuffle(idx)\n",
    "\n",
    "    # Compute split sizes\n",
    "    r_tr, r_va, r_te = ratios\n",
    "    n_tr = int(n * r_tr)\n",
    "    n_va = int(n * r_va)\n",
    "\n",
    "    # Split indices\n",
    "    tr_idx = idx[:n_tr]\n",
    "    va_idx = idx[n_tr:n_tr + n_va]\n",
    "    te_idx = idx[n_tr + n_va:]\n",
    "\n",
    "    return tr_idx, va_idx, te_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034a3795-179d-4abb-a73f-d32a88fa416e",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e9a670e-c40a-46c3-b052-687911a12b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: (16065, 17)\n",
      "Columns: ['top_agency', 'sub_agency', 'issue_area', 'program_title', 'objectives', 'trust', 'efficacy', 'knowledge', 'message', 'prompt_used', 'tag_string', 'agency_issue_pair', 'quality_validated', 'quality_status', 'repaired', 'generation_attempts_repair', 'notes']\n",
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 252/252 [00:42<00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved X_ALL.npy with shape (16065, 384)\n"
     ]
    }
   ],
   "source": [
    "# 1) Data\n",
    "df = load_data(DATA_PATH, TEXT_COL)\n",
    "print(\"Loaded:\", df.shape)\n",
    "print(\"Columns:\", list(df.columns))\n",
    "# Optional: create concatenated column for top_agency + issue_area\n",
    "if all(c in df.columns for c in [\"top_agency\", \"issue_area\"]):\n",
    "    df[\"top_agency_issue_area_concat\"] = (\n",
    "        df[\"top_agency\"].astype(str) + \" | \" + df[\"issue_area\"].astype(str)\n",
    "    )\n",
    "texts = df[TEXT_COL].tolist()\n",
    "\n",
    "# 2) Convert to / Load Embedding\n",
    "# You likely don't have s4_data/X_ALL.npy yet, so this will compute the embeddings\n",
    "if os.path.exists(\"s4_data/X_ALL.npy\"):\n",
    "    print(\"Loading precomputed embeddings...\")\n",
    "    X_ALL = np.load(\"s4_data/X_ALL.npy\")\n",
    "    print(f\"Loaded X_ALL.npy with shape {X_ALL.shape}\")\n",
    "else:\n",
    "    print(\"Computing embeddings...\")\n",
    "    X_ALL = embed_all(texts, batch_size=64, normalize=True)\n",
    "    np.save(\"s4_data/X_ALL.npy\", X_ALL)\n",
    "    print(f\"Saved X_ALL.npy with shape {X_ALL.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d0ff132-1362-436b-bb34-f222d1925b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new split indices...\n",
      "Saved TR/VA/TE indices to s4_data/\n",
      "Processing label column: top_agency\n",
      "Split ready.\n"
     ]
    }
   ],
   "source": [
    "# 3) Split (load-or-create, shared indices across all labels)\n",
    "split_dir = \"s4_data\"\n",
    "os.makedirs(split_dir, exist_ok=True)\n",
    "\n",
    "tr_path = f\"{split_dir}/TR_IDX.npy\"\n",
    "va_path = f\"{split_dir}/VA_IDX.npy\"\n",
    "te_path = f\"{split_dir}/TE_IDX.npy\"\n",
    "\n",
    "# load-or-create\n",
    "if os.path.exists(tr_path) and os.path.exists(va_path) and os.path.exists(te_path):\n",
    "    print(\"Loading existing split indices...\")\n",
    "    TR_IDX = np.load(tr_path)\n",
    "    VA_IDX = np.load(va_path)\n",
    "    TE_IDX = np.load(te_path)\n",
    "else:\n",
    "    print(\"Creating new split indices...\")\n",
    "    TR_IDX, VA_IDX, TE_IDX = split_indices(len(df))\n",
    "    np.save(tr_path, TR_IDX)\n",
    "    np.save(va_path, VA_IDX)\n",
    "    np.save(te_path, TE_IDX)\n",
    "    print(\"Saved TR/VA/TE indices to s4_data/\")\n",
    "\n",
    "# embedding split\n",
    "X_tr = X_ALL[TR_IDX]\n",
    "X_va = X_ALL[VA_IDX]\n",
    "X_te = X_ALL[TE_IDX]\n",
    "\n",
    "# label split\n",
    "y_tr = {}\n",
    "y_va = {}\n",
    "y_te = {}\n",
    "label_encoders = {}\n",
    "\n",
    "for label_name in LABEL_COLS:\n",
    "    print(f\"Processing label column: {label_name}\")\n",
    "    labels_raw = df[label_name].to_numpy()\n",
    "\n",
    "    # LabelEncoder: string → int id\n",
    "    le = LabelEncoder()\n",
    "    y_all_int = le.fit_transform(labels_raw)\n",
    "    label_encoders[label_name] = le\n",
    "\n",
    "    y_tr[label_name] = y_all_int[TR_IDX]\n",
    "    y_va[label_name] = y_all_int[VA_IDX]\n",
    "    y_te[label_name] = y_all_int[TE_IDX]\n",
    "\n",
    "print(\"Split ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9d4c91-0498-4477-abad-59a9a9cdcbc6",
   "metadata": {},
   "source": [
    "## Contrastive Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "822bc56f-5f5e-406a-99b6-9ee4505be515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training contrastive projection head (X -> Z) using top_agency labels...\n",
      "Using device: cpu\n",
      "Epoch 01 | SupCon loss = 4.9465 | val F1_macro = 0.6906\n",
      "Epoch 02 | SupCon loss = 4.5314 | val F1_macro = 0.7586\n",
      "Epoch 03 | SupCon loss = 4.3167 | val F1_macro = 0.7851\n",
      "Epoch 04 | SupCon loss = 4.1669 | val F1_macro = 0.7936\n",
      "Epoch 05 | SupCon loss = 4.0222 | val F1_macro = 0.7990\n",
      "Epoch 06 | SupCon loss = 3.9108 | val F1_macro = 0.7974\n",
      "Epoch 07 | SupCon loss = 3.8135 | val F1_macro = 0.8056\n",
      "Epoch 08 | SupCon loss = 3.7315 | val F1_macro = 0.8006\n",
      "Epoch 09 | SupCon loss = 3.6456 | val F1_macro = 0.8028\n",
      "Epoch 10 | SupCon loss = 3.5804 | val F1_macro = 0.7997\n",
      "Best val F1_macro = 0.8056\n",
      "Z shapes: (9639, 256) (3213, 256) (3213, 256)\n"
     ]
    }
   ],
   "source": [
    "# 4) Contrastive learning: X -> Z  (using top_agency as supervision, val for best epoch)\n",
    "\n",
    "print(\"Training contrastive projection head (X -> Z) using top_agency labels...\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "y_tr_super = y_tr[\"top_agency\"]\n",
    "y_va_super = y_va[\"top_agency\"]\n",
    "\n",
    "X_tr_t = torch.from_numpy(X_tr).float()\n",
    "y_tr_t = torch.from_numpy(y_tr_super).long()\n",
    "\n",
    "dataset = TensorDataset(X_tr_t, y_tr_t)\n",
    "loader = DataLoader(dataset, batch_size=256, shuffle=True, drop_last=True)\n",
    "\n",
    "in_dim = X_tr.shape[1]\n",
    "proj_dim = 256\n",
    "\n",
    "class ProjectionHead(nn.Module):\n",
    "    \"\"\"Projection head for contrastive learning.\"\"\"\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, out_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass to project input features.\"\"\"\n",
    "        z = self.net(x)\n",
    "        z = F.normalize(z, dim=1)\n",
    "        return z\n",
    "\n",
    "model = ProjectionHead(in_dim, proj_dim).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "temperature = 0.3\n",
    "epochs = 10\n",
    "\n",
    "def supervised_contrastive_loss(z, labels, temperature=0.1):\n",
    "    \"\"\"Compute supervised contrastive loss.\"\"\"\n",
    "    \n",
    "    z = F.normalize(z, dim=1)\n",
    "    sim = torch.matmul(z, z.T) / temperature  # [B, B]\n",
    "\n",
    "    batch_size = z.size(0)\n",
    "    labels = labels.contiguous().view(-1, 1)  # [B, 1]\n",
    "\n",
    "    matches = torch.eq(labels, labels.T) \n",
    "    self_mask = torch.eye(batch_size, dtype=torch.bool, device=z.device)\n",
    "    matches = matches & ~self_mask\n",
    "\n",
    "    logits_mask = ~self_mask\n",
    "    exp_sim = torch.exp(sim) * logits_mask\n",
    "\n",
    "    log_prob = sim - torch.log(exp_sim.sum(dim=1, keepdim=True) + 1e-9)\n",
    "\n",
    "    pos_sum = (matches * log_prob).sum(dim=1)\n",
    "    pos_count = matches.sum(dim=1)\n",
    "\n",
    "    mask_non_zero = pos_count > 0\n",
    "    mean_log_prob_pos = pos_sum[mask_non_zero] / (pos_count[mask_non_zero] + 1e-9)\n",
    "\n",
    "    loss = -mean_log_prob_pos.mean()\n",
    "    return loss\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def build_centroids(X, y):\n",
    "    \"\"\" Build class centroids from embeddings and labels. \"\"\"\n",
    "    centroids = {}\n",
    "    for lab in np.unique(y):\n",
    "        centroids[lab] = X[y == lab].mean(axis=0)\n",
    "    return centroids\n",
    "\n",
    "def predict_with_centroids(X, centroids):\n",
    "    \"\"\" Predict labels based on nearest centroids using cosine similarity. \"\"\"\n",
    "    labels = np.array(list(centroids.keys()))\n",
    "    C = np.vstack([centroids[lab] for lab in labels])\n",
    "\n",
    "    Xn = X / (np.linalg.norm(X, axis=1, keepdims=True) + 1e-8)\n",
    "    Cn = C / (np.linalg.norm(C, axis=1, keepdims=True) + 1e-8)\n",
    "\n",
    "    sims = Xn @ Cn.T\n",
    "    idx = sims.argmax(axis=1)\n",
    "    return labels[idx]\n",
    "\n",
    "best_va_f1 = -1.0\n",
    "best_state = None\n",
    "\n",
    "model.train()\n",
    "for epoch in range(1, epochs + 1):\n",
    "    running_loss = 0.0\n",
    "    n_batches = 0\n",
    "\n",
    "    for xb, yb in loader:\n",
    "        xb = xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        z = model(xb)\n",
    "        loss = supervised_contrastive_loss(z, yb, temperature)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        n_batches += 1\n",
    "\n",
    "    avg_loss = running_loss / max(n_batches, 1)\n",
    "    print(f\"Epoch {epoch:02d} | SupCon loss = {avg_loss:.4f}\", end=\"\")\n",
    "\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        Z_tr_tmp = model(torch.from_numpy(X_tr).float().to(device)).cpu().numpy()\n",
    "        Z_va_tmp = model(torch.from_numpy(X_va).float().to(device)).cpu().numpy()\n",
    "\n",
    "    centroids_tmp = build_centroids(Z_tr_tmp, y_tr_super)\n",
    "    y_va_pred_tmp = predict_with_centroids(Z_va_tmp, centroids_tmp)\n",
    "    f1_va_tmp = f1_score(y_va_super, y_va_pred_tmp, average=\"macro\")\n",
    "    print(f\" | val F1_macro = {f1_va_tmp:.4f}\")\n",
    "\n",
    "    if f1_va_tmp > best_va_f1:\n",
    "        best_va_f1 = f1_va_tmp\n",
    "        best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "\n",
    "    model.train()\n",
    "\n",
    "print(f\"Best val F1_macro = {best_va_f1:.4f}\")\n",
    "\n",
    "if best_state is not None:\n",
    "    model.load_state_dict(best_state)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    Z_tr = model(torch.from_numpy(X_tr).float().to(device)).cpu().numpy()\n",
    "    Z_va = model(torch.from_numpy(X_va).float().to(device)).cpu().numpy()\n",
    "    Z_te = model(torch.from_numpy(X_te).float().to(device)).cpu().numpy()\n",
    "\n",
    "print(\"Z shapes:\", Z_tr.shape, Z_va.shape, Z_te.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25485c77-3801-42e3-aa24-5bc27ee4135b",
   "metadata": {},
   "source": [
    "## Centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "32a142ed-87a4-4104-9cdb-fbd499f7ccee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Centroid classifier on X (Titan raw embedding) ===\n",
      "Accuracy      : 0.6026\n",
      "F1 (macro)    : 0.6036\n",
      "F1 (weighted) : 0.6060\n",
      "\n",
      "Classification report (truncated):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.706     0.632     0.667       152\n",
      "           1      0.829     0.534     0.650       191\n",
      "           2      0.697     0.485     0.572       171\n",
      "           3      0.638     0.777     0.701       202\n",
      "           4      0.814     0.679     0.741       187\n",
      "           5      0.397     0.370     0.383       162\n",
      "           6      0.562     0.489     0.523       184\n",
      "           7      0.598     0.718     0.652       209\n",
      "           8      0.536     0.513     0.524       189\n",
      "           9      0.477     0.595     0.529       190\n",
      "          10      0.354     0.586     0.441       186\n",
      "          11      0.713     0.641     0.676       198\n",
      "          12      0.870     0.870     0.870       215\n",
      "          13      0.673     0.532     0.594       201\n",
      "          14      0.563     0.673     0.613       199\n",
      "          15      0.845     0.753     0.796       174\n",
      "          16      0.330     0.325     0.328       203\n",
      "\n",
      "    accuracy                          0.603      3213\n",
      "   macro avg      0.624     0.598     0.604      3213\n",
      "weighted avg      0.624     0.603     0.606      3213\n",
      "\n",
      "\n",
      "=== Centroid classifier on Z (contrastive embedding) ===\n",
      "Accuracy      : 0.8030\n",
      "F1 (macro)    : 0.8032\n",
      "F1 (weighted) : 0.8046\n",
      "\n",
      "Classification report (truncated):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.930     0.789     0.854       152\n",
      "           1      0.768     0.817     0.792       191\n",
      "           2      0.851     0.836     0.844       171\n",
      "           3      0.827     0.851     0.839       202\n",
      "           4      0.918     0.834     0.874       187\n",
      "           5      0.673     0.710     0.691       162\n",
      "           6      0.768     0.793     0.781       184\n",
      "           7      0.792     0.785     0.788       209\n",
      "           8      0.837     0.815     0.826       189\n",
      "           9      0.630     0.753     0.686       190\n",
      "          10      0.811     0.828     0.819       186\n",
      "          11      0.821     0.788     0.804       198\n",
      "          12      0.939     0.926     0.932       215\n",
      "          13      0.890     0.801     0.843       201\n",
      "          14      0.779     0.764     0.772       199\n",
      "          15      0.692     0.787     0.737       174\n",
      "          16      0.800     0.749     0.774       203\n",
      "\n",
      "    accuracy                          0.803      3213\n",
      "   macro avg      0.807     0.802     0.803      3213\n",
      "weighted avg      0.809     0.803     0.805      3213\n",
      "\n"
     ]
    }
   ],
   "source": [
    "label_name = \"top_agency\"\n",
    "\n",
    "y_tr_top = y_tr[label_name]\n",
    "y_va_top = y_va[label_name]\n",
    "y_te_top = y_te[label_name]\n",
    "\n",
    "def build_centroids(X, y):\n",
    "    \"\"\" Build class centroids from embeddings and labels. \"\"\"\n",
    "    centroids = {}\n",
    "    for lab in np.unique(y):\n",
    "        centroids[lab] = X[y == lab].mean(axis=0)\n",
    "    return centroids\n",
    "\n",
    "def predict_with_centroids(X, centroids):\n",
    "    \"\"\" Predict labels based on nearest centroids using cosine similarity. \"\"\"\n",
    "    labels = np.array(list(centroids.keys()))\n",
    "    C = np.vstack([centroids[lab] for lab in labels])  # [n_classes, dim]\n",
    "\n",
    "    Xn = X / (np.linalg.norm(X, axis=1, keepdims=True) + 1e-8)\n",
    "    Cn = C / (np.linalg.norm(C, axis=1, keepdims=True) + 1e-8)\n",
    "\n",
    "    # cosine similarity: [n_samples, n_classes]\n",
    "    sims = Xn @ Cn.T\n",
    "    idx = sims.argmax(axis=1)\n",
    "    return labels[idx]\n",
    "\n",
    "\n",
    "def eval_centroid(name, X_tr_, X_te_, y_tr_, y_te_):\n",
    "    \"\"\" Evaluate centroid classifier on given data. \"\"\"\n",
    "    print(f\"\\n=== Centroid classifier on {name} ===\")\n",
    "    centroids = build_centroids(X_tr_, y_tr_)\n",
    "    y_pred = predict_with_centroids(X_te_, centroids)\n",
    "\n",
    "    acc = accuracy_score(y_te_, y_pred)\n",
    "    f1_macro = f1_score(y_te_, y_pred, average=\"macro\")\n",
    "    f1_weighted = f1_score(y_te_, y_pred, average=\"weighted\")\n",
    "\n",
    "    print(f\"Accuracy      : {acc:.4f}\")\n",
    "    print(f\"F1 (macro)    : {f1_macro:.4f}\")\n",
    "    print(f\"F1 (weighted) : {f1_weighted:.4f}\")\n",
    "    print(\"\\nClassification report (truncated):\")\n",
    "    print(classification_report(y_te_, y_pred, digits=3))\n",
    "\n",
    "    return centroids, y_pred\n",
    "\n",
    "\n",
    "# 1) X -> centroids\n",
    "centroids_X, y_pred_X = eval_centroid(\n",
    "    \"X (Titan raw embedding)\", X_tr, X_te, y_tr_top, y_te_top\n",
    ")\n",
    "\n",
    "# 2) Z -> centroids\n",
    "centroids_Z, y_pred_Z = eval_centroid(\n",
    "    \"Z (contrastive embedding)\", Z_tr, Z_te, y_tr_top, y_te_top\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd92983-e54b-4127-aee1-f46582ccd9f0",
   "metadata": {},
   "source": [
    "## Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a384b81-b647-4c33-bb10-94d74c9f780d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shapes: (9639, 384) (3213, 384) (3213, 384)\n",
      "Z shapes: (9639, 256) (3213, 256) (3213, 256)\n",
      "y sizes : (9639,) (3213,) (3213,)\n",
      "\n",
      "=== Baseline: label embedding cosine (TEST) ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST (label-embedding cosine)\n",
      "  accuracy : 0.3442\n",
      "  f1_macro : 0.3193\n",
      "\n",
      "=== Bayesian: GaussianNB on Z (TEST) ===\n",
      "TEST (GaussianNB on Z)\n",
      "  accuracy : 0.8017\n",
      "  f1_macro : 0.8041\n",
      "\n",
      "=== kNN on Z (TEST) ===\n",
      "TEST (kNN on Z, k=3)\n",
      "  accuracy : 0.8017\n",
      "  f1_macro : 0.8009\n",
      "TEST (kNN on Z, k=5)\n",
      "  accuracy : 0.8024\n",
      "  f1_macro : 0.8020\n",
      "TEST (kNN on Z, k=10)\n",
      "  accuracy : 0.8033\n",
      "  f1_macro : 0.8031\n"
     ]
    }
   ],
   "source": [
    "print(\"X shapes:\", X_tr.shape, X_va.shape, X_te.shape)\n",
    "print(\"Z shapes:\", Z_tr.shape, Z_va.shape, Z_te.shape)\n",
    "print(\"y sizes :\", y_tr_top.shape, y_va_top.shape, y_te_top.shape)\n",
    "\n",
    "def simple_metrics(title, y_true, y_pred):\n",
    "    \"\"\" Compute and print simple accuracy and F1-macro metrics. \"\"\"\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1_macro = f1_score(y_true, y_pred, average=\"macro\")\n",
    "    print(title)\n",
    "    print(f\"  accuracy : {acc:.4f}\")\n",
    "    print(f\"  f1_macro : {f1_macro:.4f}\")\n",
    "    return acc, f1_macro\n",
    "\n",
    "\n",
    "# ======================================\n",
    "# 1) Baseline: label embedding + cosine\n",
    "# ======================================\n",
    "print(\"\\n=== Baseline: label embedding cosine (TEST) ===\")\n",
    "\n",
    "# label encoder and class ids\n",
    "le_top = label_encoders[label_name]\n",
    "classes = np.unique(y_tr_top)\n",
    "class_texts = le_top.inverse_transform(classes)\n",
    "\n",
    "# embed labels using Titan\n",
    "label_vecs = embed_all(\n",
    "    list(class_texts),\n",
    "    dimensions=X_tr.shape[1],\n",
    "    normalize=True,\n",
    ")\n",
    "\n",
    "label_vecs = label_vecs / (np.linalg.norm(label_vecs, axis=1, keepdims=True) + 1e-8)\n",
    "\n",
    "# normalize X_te\n",
    "X_te_norm = X_te / (np.linalg.norm(X_te, axis=1, keepdims=True) + 1e-8)\n",
    "\n",
    "# cosine similarity = dot product\n",
    "sims = X_te_norm @ label_vecs.T\n",
    "idx = sims.argmax(axis=1)\n",
    "y_te_label_cos = classes[idx]\n",
    "\n",
    "simple_metrics(\"TEST (label-embedding cosine)\", y_te_top, y_te_label_cos)\n",
    "\n",
    "\n",
    "# ======================================\n",
    "# 2) Bayesian: GaussianNB on Z\n",
    "# ======================================\n",
    "print(\"\\n=== Bayesian: GaussianNB on Z (TEST) ===\")\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(Z_tr, y_tr_top)\n",
    "\n",
    "y_te_gnb = gnb.predict(Z_te)\n",
    "simple_metrics(\"TEST (GaussianNB on Z)\", y_te_top, y_te_gnb)\n",
    "\n",
    "\n",
    "# ======================================\n",
    "# 3) kNN on Z (TEST)\n",
    "# ======================================\n",
    "print(\"\\n=== kNN on Z (TEST) ===\")\n",
    "\n",
    "for k in [3, 5, 10]:\n",
    "    knn = KNeighborsClassifier(\n",
    "        n_neighbors=k,\n",
    "        metric=\"euclidean\",\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    knn.fit(Z_tr, y_tr_top)\n",
    "\n",
    "    y_te_knn = knn.predict(Z_te)\n",
    "    simple_metrics(f\"TEST (kNN on Z, k={k})\", y_te_top, y_te_knn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91732f63-fd22-4111-96d0-876e75c7db78",
   "metadata": {},
   "source": [
    "## Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b6b94547-c134-4bc3-bd4d-a4ca45fac8ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Centroid classifier on Z (TEST) ===\n",
      "Accuracy      : 0.8030\n",
      "F1 (macro)    : 0.8032\n",
      "F1 (weighted) : 0.8046\n",
      "\n",
      "Full classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.930     0.789     0.854       152\n",
      "           1      0.768     0.817     0.792       191\n",
      "           2      0.851     0.836     0.844       171\n",
      "           3      0.827     0.851     0.839       202\n",
      "           4      0.918     0.834     0.874       187\n",
      "           5      0.673     0.710     0.691       162\n",
      "           6      0.768     0.793     0.781       184\n",
      "           7      0.792     0.785     0.788       209\n",
      "           8      0.837     0.815     0.826       189\n",
      "           9      0.630     0.753     0.686       190\n",
      "          10      0.811     0.828     0.819       186\n",
      "          11      0.821     0.788     0.804       198\n",
      "          12      0.939     0.926     0.932       215\n",
      "          13      0.890     0.801     0.843       201\n",
      "          14      0.779     0.764     0.772       199\n",
      "          15      0.692     0.787     0.737       174\n",
      "          16      0.800     0.749     0.774       203\n",
      "\n",
      "    accuracy                          0.803      3213\n",
      "   macro avg      0.807     0.802     0.803      3213\n",
      "weighted avg      0.809     0.803     0.805      3213\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "# final evaluation: centroid classifier on Z (TEST set)\n",
    "\n",
    "print(\"\\n=== Centroid classifier on Z (TEST) ===\")\n",
    "\n",
    "# reuse previously defined build_centroids / predict_with_centroids\n",
    "centroids_Z = build_centroids(Z_tr, y_tr_top)\n",
    "y_te_cent = predict_with_centroids(Z_te, centroids_Z)\n",
    "\n",
    "acc = accuracy_score(y_te_top, y_te_cent)\n",
    "f1_macro = f1_score(y_te_top, y_te_cent, average=\"macro\")\n",
    "f1_weighted = f1_score(y_te_top, y_te_cent, average=\"weighted\")\n",
    "\n",
    "print(f\"Accuracy      : {acc:.4f}\")\n",
    "print(f\"F1 (macro)    : {f1_macro:.4f}\")\n",
    "print(f\"F1 (weighted) : {f1_weighted:.4f}\")\n",
    "print(\"\\nFull classification report:\")\n",
    "print(classification_report(y_te_top, y_te_cent, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3247b0c0-118b-4f62-b016-3b23eb621928",
   "metadata": {},
   "source": [
    "## Error Analysis\n",
    "\n",
    "### Annotation\n",
    "- Config\n",
    "    - `LABEL_COLS = [\"top_agency\"]`\n",
    "- Split\n",
    "    - `TR_IDX, VA_IDX, TE_IDX`: integer arrays of row indices into df ->\n",
    "        - `X_tr, X_va, X_te`: text embeddings split by index\n",
    "        - `y_tr, y_va, y_te`: (!dict) label names split by index\n",
    "- Contrastive Learning\n",
    "    - `X_tr, X_va` -> `Z_tr, Z_va, Z_te`: remapped text embeddings split by index\n",
    "- Main\n",
    "    - `y_tr_top, y_va_top, y_te_top`: (no longer a dict! ready to be used) label names split by index\n",
    "- Centroids\n",
    "    - `y_te_cent`: predicted label using centroids\n",
    "- Compare\n",
    "    - `y_te_label_cos, y_te_gnb, y_te_knn`: predicted label on test set using corresponding approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a748d93-e05c-44c0-9514-d5b0ae0cf514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified (local): [ 1  3  9 10 11 15 16 21 31 47 58 59 62 67 68 69 83 88 90 98]\n",
      "Misclassified (global df indexes): [ 8964 11754  4531  9866   365 16034   147  8599  6230  8980  6272  8616\n",
      "    16 13199  3493  9651  2355  4592  8656  6356]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "y_true = np.asarray(y_te_top)\n",
    "y_pred = np.asarray(y_te_cent)   # or y_te_label_cos, y_te_gnb, y_te_knn\n",
    "\n",
    "# 1. misclassified positions INSIDE the test split\n",
    "mis_local_idx = np.where(y_true != y_pred)[0]\n",
    "\n",
    "print(\"Misclassified (local):\", mis_local_idx[:20])\n",
    "\n",
    "# 2. convert to original df indexes\n",
    "mis_global_idx = TE_IDX[mis_local_idx]\n",
    "\n",
    "print(\"Misclassified (global df indexes):\", mis_global_idx[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a82a86-fb7b-4f72-847d-38996c0713f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose your prediction method: \"cent\", \"label_cos\", \"gnb\", or \"knn\"\n",
    "METHOD = \"cent\"\n",
    "\n",
    "# map method name → predicted label vector\n",
    "pred_map = {\n",
    "    \"cent\": y_te_cent,\n",
    "    \"label_cos\": y_te_label_cos,\n",
    "    \"gnb\": y_te_gnb,\n",
    "    \"knn\": y_te_knn,\n",
    "}\n",
    "\n",
    "y_true = np.asarray(y_te_top)\n",
    "y_pred = np.asarray(pred_map[METHOD])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a8f1e4-27e3-4950-9fe7-bf318ed0ddf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total misclassified samples (cent): 577\n",
      "\n",
      "First 20 global misclassified indexes:\n",
      "[ 8964 11754  4531  9866   365 16034   147  8599  6230  8980  6272  8616\n",
      "    16 13199  3493  9651  2355  4592  8656  6356]\n"
     ]
    }
   ],
   "source": [
    "# local positions within the test split\n",
    "mis_local_idx = np.where(y_true != y_pred)[0]\n",
    "print(f\"Total misclassified samples ({METHOD}):\", len(mis_local_idx))\n",
    "\n",
    "# convert to original dataframe row indices\n",
    "mis_global_idx = TE_IDX[mis_local_idx]\n",
    "\n",
    "print(\"\\nFirst 20 global misclassified indexes:\")\n",
    "print(mis_global_idx[:20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd86cec-782d-47d1-b600-a761327b13bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = label_encoders[\"top_agency\"]\n",
    "\n",
    "true_names = le.inverse_transform(y_te_top[mis_local_idx])\n",
    "pred_names = le.inverse_transform(y_pred[mis_local_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb72ddc-632c-4353-8840-7140563357f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>global_idx</th>\n",
       "      <th>local_te_idx</th>\n",
       "      <th>true_label</th>\n",
       "      <th>pred_label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8964</td>\n",
       "      <td>1</td>\n",
       "      <td>Department of Labor</td>\n",
       "      <td>Other Independent Federal Agency or Commission</td>\n",
       "      <td>this model is not designed to give legal, fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11754</td>\n",
       "      <td>3</td>\n",
       "      <td>Department of Veteran's Affairs (VA)</td>\n",
       "      <td>Executive Office of the President</td>\n",
       "      <td>is writing to express her support for and ask ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4531</td>\n",
       "      <td>9</td>\n",
       "      <td>Department of Energy</td>\n",
       "      <td>Other Independent Federal Agency or Commission</td>\n",
       "      <td>dear senator/representative, i'm writing to in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9866</td>\n",
       "      <td>10</td>\n",
       "      <td>Department of State</td>\n",
       "      <td>Department of Health and Human Services (HHS)</td>\n",
       "      <td>dear senator/representative: my name is aliyu ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>365</td>\n",
       "      <td>11</td>\n",
       "      <td>Department of Agriculture (USDA)</td>\n",
       "      <td>Executive Office of the President</td>\n",
       "      <td>dear senator/representative , as an american a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   global_idx  local_te_idx                            true_label  \\\n",
       "0        8964             1                   Department of Labor   \n",
       "1       11754             3  Department of Veteran's Affairs (VA)   \n",
       "2        4531             9                  Department of Energy   \n",
       "3        9866            10                   Department of State   \n",
       "4         365            11      Department of Agriculture (USDA)   \n",
       "\n",
       "                                       pred_label  \\\n",
       "0  Other Independent Federal Agency or Commission   \n",
       "1               Executive Office of the President   \n",
       "2  Other Independent Federal Agency or Commission   \n",
       "3   Department of Health and Human Services (HHS)   \n",
       "4               Executive Office of the President   \n",
       "\n",
       "                                             message  \n",
       "0  this model is not designed to give legal, fina...  \n",
       "1  is writing to express her support for and ask ...  \n",
       "2  dear senator/representative, i'm writing to in...  \n",
       "3  dear senator/representative: my name is aliyu ...  \n",
       "4  dear senator/representative , as an american a...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#true_names = label_encoder.inverse_transform(y_true[mis_local_idx])\n",
    "#pred_names = label_encoder.inverse_transform(y_pred[mis_local_idx])\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df_errors = pd.DataFrame({\n",
    "    \"global_idx\": mis_global_idx,\n",
    "    \"local_te_idx\": mis_local_idx,\n",
    "    \"true_label\": y_true[mis_local_idx],\n",
    "    \"pred_label\": y_pred[mis_local_idx],\n",
    "    \"message\": df.loc[mis_global_idx, \"message\"].values,\n",
    "    \"true_label\": true_names,\n",
    "    \"pred_label\": pred_names\n",
    "})\n",
    "\n",
    "df_errors.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091069d3-3703-47b7-b61a-cc2937b24062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: misclassified_messages.xlsx\n"
     ]
    }
   ],
   "source": [
    "#!pip install openpyxl\n",
    "\n",
    "# Export misclassified messages to Excel\n",
    "output_path = \"misclassified_messages.xlsx\"\n",
    "df_errors.to_excel(output_path, index=False)\n",
    "\n",
    "print(\"Saved to:\", output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcab7655-c5aa-4ac7-b8ee-59372a7e5a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: misclassified_sample20.xlsx\n"
     ]
    }
   ],
   "source": [
    "sample = df_errors.sample(n=20, random_state=42)\n",
    "\n",
    "output_path = \"misclassified_sample20.xlsx\"\n",
    "sample.to_excel(output_path, index=False)\n",
    "\n",
    "print(\"Saved to:\", output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
